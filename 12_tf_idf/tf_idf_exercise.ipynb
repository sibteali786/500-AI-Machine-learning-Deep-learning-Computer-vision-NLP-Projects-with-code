{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sibteali786/500-AI-Machine-learning-Deep-learning-Computer-vision-NLP-Projects-with-code/blob/main/12_tf_idf/tf_idf_exercise.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eVrcHNZpQLUz"
      },
      "source": [
        "### **TF-IDF: Exercises**\n",
        "\n",
        "- Humans ðŸ‘¦ show different emotions/feelings based on the situations and communicate them through facial expressions or in form of words.\n",
        "\n",
        "- In Social Media like Twitter and Instagram, many people express their views through comments about a particular event/scenario and these comments may address the feelings like sadness, happiness, joy, sarcasm, fear, and many other.\n",
        "\n",
        "- For a given comment/text, we are going to use classical NLP techniques and classify under which emotion that particular comment belongs!\n",
        "\n",
        "- We are going to use techniques like Bag of grams, n-grams, TF-IDF, etc. for text representation and apply different classification algorithms."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wU5KDovsV9ez"
      },
      "source": [
        "### **About Data: Emotion Detection**\n",
        "\n",
        "Credits: https://www.kaggle.com/datasets/praveengovi/emotions-dataset-for-nlp\n",
        "\n",
        "\n",
        "- This data consists of two columns.\n",
        "        - Comment\n",
        "        - Emotion\n",
        "- Comment are the statements or messages regarding to a particular event/situation.\n",
        "\n",
        "- Emotion feature tells whether the given comment is fear ðŸ˜¨, Anger ðŸ˜¡, Joy ðŸ˜‚.\n",
        "\n",
        "- As there are only 3 classes, this problem comes under the **Multi-Class Classification.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8ML2s0KWVXmv"
      },
      "outputs": [],
      "source": [
        "#import pandas library\n",
        "\n",
        "\n",
        "#read the dataset with name \"Emotion_classify_Data.csv\" and store it in a variable df\n",
        "\n",
        "\n",
        "#print the shape of dataframe\n",
        "\n",
        "\n",
        "#print top 5 rows\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "joLuZmFpT-fY"
      },
      "outputs": [],
      "source": [
        "#check the distribution of Emotion\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qPxiqT_TT-hx"
      },
      "outputs": [],
      "source": [
        "#Add the new column \"Emotion_num\" which gives a unique number to each of these Emotions\n",
        "#joy --> 0, fear --> 1, anger --> 2\n",
        "\n",
        "\n",
        "#checking the results by printing top 5 rows\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PE-c0zbDXTEm"
      },
      "source": [
        "### **Modelling without Pre-processing Text data**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NjJqi7UBT-nr"
      },
      "outputs": [],
      "source": [
        "#import train-test split\n",
        "\n",
        "\n",
        "#Do the 'train-test' splitting with test size of 20%\n",
        "#Note: Give Random state 2022 and also do the stratify sampling\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5lAD0iqGcdCn"
      },
      "outputs": [],
      "source": [
        "#print the shapes of X_train and X_test\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t57hw7gOVXuW"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u6h8ZZLxZd79"
      },
      "source": [
        "\n",
        "**Attempt 1** :\n",
        "\n",
        "1. using the sklearn pipeline module create a classification pipeline to classify the Data.\n",
        "\n",
        "**Note:**\n",
        "- using CountVectorizer with only trigrams.\n",
        "- use **RandomForest** as the classifier.\n",
        "- print the classification report.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vGg2iXv6g40l"
      },
      "outputs": [],
      "source": [
        "#import CountVectorizer, RandomForest, pipeline, classification_report from sklearn\n",
        "\n",
        "\n",
        "#1. create a pipeline object\n",
        "\n",
        "\n",
        "\n",
        "#2. fit with X_train and y_train\n",
        "\n",
        "\n",
        "\n",
        "#3. get the predictions for X_test and store it in y_pred\n",
        "\n",
        "\n",
        "\n",
        "#4. print the classfication report\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I08-kc_JYCNL"
      },
      "source": [
        "\n",
        "**Attempt 2** :\n",
        "\n",
        "1. using the sklearn pipeline module create a classification pipeline to classify the Data.\n",
        "\n",
        "**Note:**\n",
        "- using CountVectorizer with both unigram and bigrams.\n",
        "- use **Multinomial Naive Bayes** as the classifier.\n",
        "- print the classification report.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8zetSmBrXmjM"
      },
      "outputs": [],
      "source": [
        "#import MultinomialNB from sklearn\n",
        "\n",
        "\n",
        "\n",
        "#1. create a pipeline object\n",
        "\n",
        "\n",
        "\n",
        "#2. fit with X_train and y_train\n",
        "\n",
        "\n",
        "\n",
        "#3. get the predictions for X_test and store it in y_pred\n",
        "\n",
        "\n",
        "#4. print the classfication report\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8Wde4r_-YwU-"
      },
      "source": [
        "\n",
        "**Attempt 3** :\n",
        "\n",
        "1. using the sklearn pipeline module create a classification pipeline to classify the Data.\n",
        "\n",
        "**Note:**\n",
        "- using CountVectorizer with both unigram and Bigrams.\n",
        "- use **RandomForest** as the classifier.\n",
        "- print the classification report.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n0dG2tc0X7SK"
      },
      "outputs": [],
      "source": [
        "#1. create a pipeline object\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#2. fit with X_train and y_train\n",
        "\n",
        "\n",
        "\n",
        "#3. get the predictions for X_test and store it in y_pred\n",
        "\n",
        "\n",
        "\n",
        "#4. print the classfication report\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hmrXmL_3Z2y6"
      },
      "source": [
        "\n",
        "**Attempt 4** :\n",
        "\n",
        "1. using the sklearn pipeline module create a classification pipeline to classify the Data.\n",
        "\n",
        "**Note:**\n",
        "- using **TF-IDF vectorizer** for Pre-processing the text.\n",
        "- use **RandomForest** as the classifier.\n",
        "- print the classification report.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "djsDsThaaCSO"
      },
      "outputs": [],
      "source": [
        "#import TfidfVectorizer from sklearn\n",
        "\n",
        "\n",
        "\n",
        "#1. create a pipeline object\n",
        "\n",
        "\n",
        "\n",
        "#2. fit with X_train and y_train\n",
        "\n",
        "\n",
        "\n",
        "#3. get the predictions for X_test and store it in y_pred\n",
        "\n",
        "\n",
        "#4. print the classfication report\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-ACq6pDkZ4sA"
      },
      "source": [
        "<h3>Use text pre-processing to remove stop words, punctuations and apply lemmatization </h3>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tj_xYgthX7UF"
      },
      "outputs": [],
      "source": [
        "import spacy\n",
        "\n",
        "# load english language model and create nlp object from it\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "\n",
        "#use this utility function to get the preprocessed text data\n",
        "def preprocess(text):\n",
        "    # remove stop words and lemmatize the text\n",
        "    doc = nlp(text)\n",
        "    filtered_tokens = []\n",
        "    for token in doc:\n",
        "        if token.is_stop or token.is_punct:\n",
        "            continue\n",
        "        filtered_tokens.append(token.lemma_)\n",
        "\n",
        "    return \" \".join(filtered_tokens)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xqW1i19wX7Xq"
      },
      "outputs": [],
      "source": [
        "# create a new column \"preprocessed_comment\" and use the utility function above to get the clean data\n",
        "# this will take some time, please be patient\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q24oRlMcai9l"
      },
      "source": [
        "**Build a model with pre processed text**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ahdd2mgxX7dM"
      },
      "outputs": [],
      "source": [
        "#Do the 'train-test' splitting with test size of 20% with random state of 2022 and stratify sampling too\n",
        "#Note: Use the preprocessed_Comment\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kqonfpeYasOE"
      },
      "source": [
        "**Let's check the scores with our best model till now**\n",
        "- Random Forest"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u1wYgFs3auLQ"
      },
      "source": [
        "**Attempt1** :\n",
        "\n",
        "1. using the sklearn pipeline module create a classification pipeline to classify the Data.\n",
        "\n",
        "**Note:**\n",
        "- using CountVectorizer with both unigrams and bigrams.\n",
        "- use **RandomForest** as the classifier.\n",
        "- print the classification report.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Khtu32z1XmmE"
      },
      "outputs": [],
      "source": [
        "#1. create a pipeline object\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#2. fit with X_train and y_train\n",
        "\n",
        "\n",
        "\n",
        "#3. get the predictions for X_test and store it in y_pred\n",
        "\n",
        "\n",
        "\n",
        "#4. print the classfication report\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U9GZPaQbbJbx"
      },
      "source": [
        "\n",
        "**Attempt 2** :\n",
        "\n",
        "1. using the sklearn pipeline module create a classification pipeline to classify the data.\n",
        "\n",
        "**Note:**\n",
        "- using **TF-IDF vectorizer** for pre-processing the text.\n",
        "- use **RandomForest** as the classifier.\n",
        "- print the classification report.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f2y1Cy4Bauxu"
      },
      "outputs": [],
      "source": [
        "#1. create a pipeline object\n",
        "\n",
        "\n",
        "\n",
        "#2. fit with X_train and y_train\n",
        "\n",
        "\n",
        "\n",
        "#3. get the predictions for X_test and store it in y_pred\n",
        "\n",
        "\n",
        "\n",
        "#4. print the classfication report"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ovt0eSkK89vX"
      },
      "source": [
        "## **Please write down Final Observations**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ta2cWBUkfKel"
      },
      "source": [
        "## [**Solution**](./tf_idf_exercise_solutions.ipynb)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "tf_idf_exercise.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}